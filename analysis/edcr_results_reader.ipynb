{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMODITY = 'copper_precision'\n",
    "\n",
    "EDCR_RESULTS_PATH = f'{COMMODITY}/test/predictions/test'\n",
    "OG_RESULTS_PATH = f'{COMMODITY}/test/results_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_filename(filename):\n",
    "    parts = filename.split(\"Rule\")\n",
    "    epsilon = parts[0].split()[-1]\n",
    "    models_base = parts[1].split(\"for\")\n",
    "    models = models_base[0].strip()\n",
    "    base = models_base[1].split(\"_predictions\")[0].strip()\n",
    "    return base, models, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df):\n",
    "    y_true = df['True']\n",
    "    y_pred = df['Predicted']\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[0, 1])\n",
    "    prior = pd.read_csv(OG_RESULTS_PATH, nrows=1)['Prior'].iloc[0]\n",
    "    return accuracy, precision, recall, f1, prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(path):\n",
    "    all_results = []  \n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith('Confident') and filename.endswith(\"_predictions.csv\"):\n",
    "            base, models, epsilon = extract_info_from_filename(filename)\n",
    "            df = pd.read_csv(os.path.join(path, filename))\n",
    "            accuracy, precision, recall, f1, prior = calculate_metrics(df)\n",
    "            row = {\n",
    "                'Base': base,\n",
    "                'Models': models,\n",
    "                'Epsilon': epsilon,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision (0)': precision[0],\n",
    "                'Recall (0)': recall[0],\n",
    "                'F1 (0)': f1[0],\n",
    "                'Precision (1)': precision[1],\n",
    "                'Recall (1)': recall[1],\n",
    "                'F1 (1)': f1[1],\n",
    "                'Prior': prior  \n",
    "            }\n",
    "            all_results.append(row)\n",
    "    \n",
    "    # Convert the list of results to a DataFrame\n",
    "    return pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results_df = process_files(EDCR_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_256_3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_64_3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.747748</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.845304</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_256_3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_64_3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.855769</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.864721</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_32</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_256_3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_64_3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.860697</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_32</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_256_3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_64_3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_32</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_256_3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_64_3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_256_3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>CNN_64_3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_128</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.908629</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_256</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>LSTM_32</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Base     Models Epsilon  Accuracy  Precision (0)  Recall (0)    F1 (0)  \\\n",
       "3   RNN_128  CNN_256_3     0.5  0.815315       0.861386    0.930481  0.894602   \n",
       "4   RNN_128   CNN_64_3     0.5  0.806306       0.860000    0.919786  0.888889   \n",
       "5   RNN_128   LSTM_128     0.5  0.747748       0.874286    0.818182  0.845304   \n",
       "6   RNN_128   LSTM_256     0.5  0.806306       0.860000    0.919786  0.888889   \n",
       "7   RNN_128    LSTM_32     0.5  0.815315       0.861386    0.930481  0.894602   \n",
       "11  RNN_128  CNN_256_3     0.6  0.828829       0.856459    0.957219  0.904040   \n",
       "12  RNN_128   CNN_64_3     0.6  0.824324       0.855769    0.951872  0.901266   \n",
       "13  RNN_128   LSTM_128     0.6  0.770270       0.857895    0.871658  0.864721   \n",
       "14  RNN_128   LSTM_256     0.6  0.833333       0.864078    0.951872  0.905852   \n",
       "15  RNN_128    LSTM_32     0.6  0.828829       0.856459    0.957219  0.904040   \n",
       "19  RNN_128  CNN_256_3     0.7  0.828829       0.856459    0.957219  0.904040   \n",
       "20  RNN_128   CNN_64_3     0.7  0.828829       0.856459    0.957219  0.904040   \n",
       "21  RNN_128   LSTM_128     0.7  0.810811       0.860697    0.925134  0.891753   \n",
       "22  RNN_128   LSTM_256     0.7  0.833333       0.860577    0.957219  0.906329   \n",
       "23  RNN_128    LSTM_32     0.7  0.828829       0.856459    0.957219  0.904040   \n",
       "27  RNN_128  CNN_256_3     0.8  0.828829       0.856459    0.957219  0.904040   \n",
       "28  RNN_128   CNN_64_3     0.8  0.828829       0.856459    0.957219  0.904040   \n",
       "29  RNN_128   LSTM_128     0.8  0.833333       0.864078    0.951872  0.905852   \n",
       "30  RNN_128   LSTM_256     0.8  0.833333       0.860577    0.957219  0.906329   \n",
       "31  RNN_128    LSTM_32     0.8  0.828829       0.856459    0.957219  0.904040   \n",
       "35  RNN_128  CNN_256_3    0.95  0.828829       0.856459    0.957219  0.904040   \n",
       "36  RNN_128   CNN_64_3    0.95  0.828829       0.856459    0.957219  0.904040   \n",
       "37  RNN_128   LSTM_128    0.95  0.833333       0.860577    0.957219  0.906329   \n",
       "38  RNN_128   LSTM_256    0.95  0.828829       0.856459    0.957219  0.904040   \n",
       "39  RNN_128    LSTM_32    0.95  0.828829       0.856459    0.957219  0.904040   \n",
       "43  RNN_128  CNN_256_3     0.9  0.828829       0.856459    0.957219  0.904040   \n",
       "44  RNN_128   CNN_64_3     0.9  0.828829       0.856459    0.957219  0.904040   \n",
       "45  RNN_128   LSTM_128     0.9  0.837838       0.864734    0.957219  0.908629   \n",
       "46  RNN_128   LSTM_256     0.9  0.828829       0.856459    0.957219  0.904040   \n",
       "47  RNN_128    LSTM_32     0.9  0.828829       0.856459    0.957219  0.904040   \n",
       "\n",
       "    Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "3        0.350000    0.200000  0.254545   0.16  \n",
       "4        0.318182    0.200000  0.245614   0.16  \n",
       "5        0.276596    0.371429  0.317073   0.16  \n",
       "6        0.318182    0.200000  0.245614   0.16  \n",
       "7        0.350000    0.200000  0.254545   0.16  \n",
       "11       0.384615    0.142857  0.208333   0.16  \n",
       "12       0.357143    0.142857  0.204082   0.16  \n",
       "13       0.250000    0.228571  0.238806   0.16  \n",
       "14       0.437500    0.200000  0.274510   0.16  \n",
       "15       0.384615    0.142857  0.208333   0.16  \n",
       "19       0.384615    0.142857  0.208333   0.16  \n",
       "20       0.384615    0.142857  0.208333   0.16  \n",
       "21       0.333333    0.200000  0.250000   0.16  \n",
       "22       0.428571    0.171429  0.244898   0.16  \n",
       "23       0.384615    0.142857  0.208333   0.16  \n",
       "27       0.384615    0.142857  0.208333   0.16  \n",
       "28       0.384615    0.142857  0.208333   0.16  \n",
       "29       0.437500    0.200000  0.274510   0.16  \n",
       "30       0.428571    0.171429  0.244898   0.16  \n",
       "31       0.384615    0.142857  0.208333   0.16  \n",
       "35       0.384615    0.142857  0.208333   0.16  \n",
       "36       0.384615    0.142857  0.208333   0.16  \n",
       "37       0.428571    0.171429  0.244898   0.16  \n",
       "38       0.384615    0.142857  0.208333   0.16  \n",
       "39       0.384615    0.142857  0.208333   0.16  \n",
       "43       0.384615    0.142857  0.208333   0.16  \n",
       "44       0.384615    0.142857  0.208333   0.16  \n",
       "45       0.466667    0.200000  0.280000   0.16  \n",
       "46       0.384615    0.142857  0.208333   0.16  \n",
       "47       0.384615    0.142857  0.208333   0.16  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_one = results_df[results_df['Models'] != 'all']\n",
    "# pd.set_option('display.max_rows', 200)\n",
    "results_df_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.780749</td>\n",
       "      <td>0.822535</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>all</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.860697</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>all</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>all</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RNN_128</td>\n",
       "      <td>all</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.908629</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Base Models Epsilon  Accuracy  Precision (0)  Recall (0)    F1 (0)  \\\n",
       "2   RNN_128    all     0.5  0.716216       0.869048    0.780749  0.822535   \n",
       "10  RNN_128    all     0.6  0.765766       0.857143    0.866310  0.861702   \n",
       "18  RNN_128    all     0.7  0.810811       0.860697    0.925134  0.891753   \n",
       "26  RNN_128    all     0.8  0.833333       0.864078    0.951872  0.905852   \n",
       "34  RNN_128    all    0.95  0.833333       0.860577    0.957219  0.906329   \n",
       "42  RNN_128    all     0.9  0.837838       0.864734    0.957219  0.908629   \n",
       "\n",
       "    Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "2        0.240741    0.371429  0.292135   0.16  \n",
       "10       0.242424    0.228571  0.235294   0.16  \n",
       "18       0.333333    0.200000  0.250000   0.16  \n",
       "26       0.437500    0.200000  0.274510   0.16  \n",
       "34       0.428571    0.171429  0.244898   0.16  \n",
       "42       0.466667    0.200000  0.280000   0.16  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_all = results_df[(results_df['Models'] == 'all') & (results_df['Base'] != \"dumb_spikes\") & (results_df['Base'] != \"dumb_non_spikes\")]\n",
    "results_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumb Model (Only Predicts Spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Base Models Epsilon  Accuracy  Precision (0)  Recall (0)  F1 (0)  \\\n",
       "1   dumb_spikes    all     0.5  0.157658            0.0         0.0     0.0   \n",
       "9   dumb_spikes    all     0.6  0.157658            0.0         0.0     0.0   \n",
       "17  dumb_spikes    all     0.7  0.157658            0.0         0.0     0.0   \n",
       "25  dumb_spikes    all     0.8  0.157658            0.0         0.0     0.0   \n",
       "33  dumb_spikes    all    0.95  0.157658            0.0         0.0     0.0   \n",
       "41  dumb_spikes    all     0.9  0.157658            0.0         0.0     0.0   \n",
       "\n",
       "    Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "1        0.157658         1.0  0.272374   0.16  \n",
       "9        0.157658         1.0  0.272374   0.16  \n",
       "17       0.157658         1.0  0.272374   0.16  \n",
       "25       0.157658         1.0  0.272374   0.16  \n",
       "33       0.157658         1.0  0.272374   0.16  \n",
       "41       0.157658         1.0  0.272374   0.16  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_all = results_df[(results_df['Models'] == 'all') & (results_df['Base'] == \"dumb_spikes\")]\n",
    "results_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumb Model (Only Predicts Non-Spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.780749</td>\n",
       "      <td>0.822535</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.864721</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.819820</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.861244</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.913151</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.854460</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Base Models Epsilon  Accuracy  Precision (0)  Recall (0)  \\\n",
       "0   dumb_non_spikes    all     0.5  0.716216       0.869048    0.780749   \n",
       "8   dumb_non_spikes    all     0.6  0.770270       0.857895    0.871658   \n",
       "16  dumb_non_spikes    all     0.7  0.819820       0.862069    0.935829   \n",
       "24  dumb_non_spikes    all     0.8  0.837838       0.861244    0.962567   \n",
       "32  dumb_non_spikes    all    0.95  0.842342       0.851852    0.983957   \n",
       "40  dumb_non_spikes    all     0.9  0.837838       0.854460    0.973262   \n",
       "\n",
       "      F1 (0)  Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "0   0.822535       0.240741    0.371429  0.292135   0.16  \n",
       "8   0.864721       0.250000    0.228571  0.238806   0.16  \n",
       "16  0.897436       0.368421    0.200000  0.259259   0.16  \n",
       "24  0.909091       0.461538    0.171429  0.250000   0.16  \n",
       "32  0.913151       0.500000    0.085714  0.146341   0.16  \n",
       "40  0.910000       0.444444    0.114286  0.181818   0.16  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_all = results_df[(results_df['Models'] == 'all') & (results_df['Base'] == \"dumb_non_spikes\")]\n",
    "results_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>256 layers</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.860697</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>128 layers</td>\n",
       "      <td>0.752252</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>64 layers</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.112299</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.139896</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>32 layers</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.900256</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>32 filters, kernel size 7</td>\n",
       "      <td>0.572072</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.214876</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>32 filters, kernel size 5</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>32 filters, kernel size 3</td>\n",
       "      <td>0.360360</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.342246</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.115108</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>64 filters, kernel size 7</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.850299</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>64 filters, kernel size 5</td>\n",
       "      <td>0.752252</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.855615</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>64 filters, kernel size 3</td>\n",
       "      <td>0.572072</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.620321</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>128 filters, kernel size 7</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.820937</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>128 filters, kernel size 5</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.884910</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>128 filters, kernel size 3</td>\n",
       "      <td>0.761261</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.855615</td>\n",
       "      <td>0.857909</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>256 filters, kernel size 7</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>0.845304</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>256 filters, kernel size 5</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>0.841530</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>256 filters, kernel size 3</td>\n",
       "      <td>0.680180</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNN</td>\n",
       "      <td>256 units</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.128342</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.142105</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RNN</td>\n",
       "      <td>128 units</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNN</td>\n",
       "      <td>64 units</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.840491</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNN</td>\n",
       "      <td>32 units</td>\n",
       "      <td>0.504505</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.647436</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CNN</td>\n",
       "      <td>32 filters, kernel size 7</td>\n",
       "      <td>0.576577</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.620321</td>\n",
       "      <td>0.711656</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CNN</td>\n",
       "      <td>32 filters, kernel size 5</td>\n",
       "      <td>0.400901</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>0.519856</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CNN</td>\n",
       "      <td>32 filters, kernel size 3</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.832117</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CNN</td>\n",
       "      <td>64 filters, kernel size 7</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.844920</td>\n",
       "      <td>0.847185</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CNN</td>\n",
       "      <td>64 filters, kernel size 5</td>\n",
       "      <td>0.481982</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.497326</td>\n",
       "      <td>0.617940</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.195804</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CNN</td>\n",
       "      <td>64 filters, kernel size 3</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CNN</td>\n",
       "      <td>128 filters, kernel size 7</td>\n",
       "      <td>0.725225</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.834688</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CNN</td>\n",
       "      <td>128 filters, kernel size 5</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.854922</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CNN</td>\n",
       "      <td>128 filters, kernel size 3</td>\n",
       "      <td>0.545045</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.683386</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CNN</td>\n",
       "      <td>256 filters, kernel size 7</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.848649</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CNN</td>\n",
       "      <td>256 filters, kernel size 5</td>\n",
       "      <td>0.369369</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.336898</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CNN</td>\n",
       "      <td>256 filters, kernel size 3</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dumb Model</td>\n",
       "      <td>spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dumb Model</td>\n",
       "      <td>non_spikes</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule LSTM_32for RNN_128</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule CNN_256_3for RNN_128</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule LSTM_256for RNN_128</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule CNN_64_3for RNN_128</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule LSTM_128for RNN_128</td>\n",
       "      <td>0.747748</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.845304</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule allfor RNN_128</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.780749</td>\n",
       "      <td>0.822535</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule allfor dumb_spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.5Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.780749</td>\n",
       "      <td>0.822535</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule LSTM_32for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule CNN_256_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule LSTM_256for RNN_128</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule CNN_64_3for RNN_128</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.855769</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule LSTM_128for RNN_128</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.864721</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule allfor RNN_128</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule allfor dumb_spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.6Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.864721</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule LSTM_32for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule CNN_256_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule LSTM_256for RNN_128</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule CNN_64_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule LSTM_128for RNN_128</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.860697</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule allfor RNN_128</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.860697</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule allfor dumb_spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.7Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.819820</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule LSTM_32for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule CNN_256_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule LSTM_256for RNN_128</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule CNN_64_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule LSTM_128for RNN_128</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule allfor RNN_128</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule allfor dumb_spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.8Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.861244</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule LSTM_32for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule CNN_256_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule LSTM_256for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule CNN_64_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule LSTM_128for RNN_128</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.908629</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule allfor RNN_128</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.908629</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule allfor dumb_spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.9Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.854460</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule LSTM_32for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule CNN_256_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule LSTM_256for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule CNN_64_3for RNN_128</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.856459</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule LSTM_128for RNN_128</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor RNN_128</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.957219</td>\n",
       "      <td>0.906329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor dumb_spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.913151</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                     Params  Accuracy  \\\n",
       "0                 LSTM                                 256 layers  0.810811   \n",
       "1                 LSTM                                 128 layers  0.752252   \n",
       "2                 LSTM                                  64 layers  0.216216   \n",
       "3                 LSTM                                  32 layers  0.824324   \n",
       "4   CNN with Attention                  32 filters, kernel size 7  0.572072   \n",
       "5   CNN with Attention                  32 filters, kernel size 5  0.621622   \n",
       "6   CNN with Attention                  32 filters, kernel size 3  0.360360   \n",
       "7   CNN with Attention                  64 filters, kernel size 7  0.684685   \n",
       "8   CNN with Attention                  64 filters, kernel size 5  0.752252   \n",
       "9   CNN with Attention                  64 filters, kernel size 3  0.572072   \n",
       "10  CNN with Attention                 128 filters, kernel size 7  0.707207   \n",
       "11  CNN with Attention                 128 filters, kernel size 5  0.797297   \n",
       "12  CNN with Attention                 128 filters, kernel size 3  0.761261   \n",
       "13  CNN with Attention                 256 filters, kernel size 7  0.720721   \n",
       "14  CNN with Attention                 256 filters, kernel size 5  0.720721   \n",
       "15  CNN with Attention                 256 filters, kernel size 3  0.680180   \n",
       "16                 RNN                                  256 units  0.229730   \n",
       "17                 RNN                                  128 units  0.828829   \n",
       "18                 RNN                                   64 units  0.657658   \n",
       "19                 RNN                                   32 units  0.504505   \n",
       "20                 CNN                  32 filters, kernel size 7  0.576577   \n",
       "21                 CNN                  32 filters, kernel size 5  0.400901   \n",
       "22                 CNN                  32 filters, kernel size 3  0.567568   \n",
       "23                 CNN                  64 filters, kernel size 7  0.743243   \n",
       "24                 CNN                  64 filters, kernel size 5  0.481982   \n",
       "25                 CNN                  64 filters, kernel size 3  0.806306   \n",
       "26                 CNN                 128 filters, kernel size 7  0.725225   \n",
       "27                 CNN                 128 filters, kernel size 5  0.774775   \n",
       "28                 CNN                 128 filters, kernel size 3  0.545045   \n",
       "29                 CNN                 256 filters, kernel size 7  0.738739   \n",
       "30                 CNN                 256 filters, kernel size 5  0.369369   \n",
       "31                 CNN                 256 filters, kernel size 3  0.815315   \n",
       "32          Dumb Model                                     spikes  0.157658   \n",
       "33          Dumb Model                                 non_spikes  0.842342   \n",
       "34                EDCR       Confident 0.5Rule LSTM_32for RNN_128  0.815315   \n",
       "35                EDCR     Confident 0.5Rule CNN_256_3for RNN_128  0.815315   \n",
       "36                EDCR      Confident 0.5Rule LSTM_256for RNN_128  0.806306   \n",
       "37                EDCR      Confident 0.5Rule CNN_64_3for RNN_128  0.806306   \n",
       "38                EDCR      Confident 0.5Rule LSTM_128for RNN_128  0.747748   \n",
       "39                EDCR           Confident 0.5Rule allfor RNN_128  0.716216   \n",
       "40                EDCR       Confident 0.5Rule allfor dumb_spikes  0.157658   \n",
       "41                EDCR   Confident 0.5Rule allfor dumb_non_spikes  0.716216   \n",
       "42                EDCR       Confident 0.6Rule LSTM_32for RNN_128  0.828829   \n",
       "43                EDCR     Confident 0.6Rule CNN_256_3for RNN_128  0.828829   \n",
       "44                EDCR      Confident 0.6Rule LSTM_256for RNN_128  0.833333   \n",
       "45                EDCR      Confident 0.6Rule CNN_64_3for RNN_128  0.824324   \n",
       "46                EDCR      Confident 0.6Rule LSTM_128for RNN_128  0.770270   \n",
       "47                EDCR           Confident 0.6Rule allfor RNN_128  0.765766   \n",
       "48                EDCR       Confident 0.6Rule allfor dumb_spikes  0.157658   \n",
       "49                EDCR   Confident 0.6Rule allfor dumb_non_spikes  0.770270   \n",
       "50                EDCR       Confident 0.7Rule LSTM_32for RNN_128  0.828829   \n",
       "51                EDCR     Confident 0.7Rule CNN_256_3for RNN_128  0.828829   \n",
       "52                EDCR      Confident 0.7Rule LSTM_256for RNN_128  0.833333   \n",
       "53                EDCR      Confident 0.7Rule CNN_64_3for RNN_128  0.828829   \n",
       "54                EDCR      Confident 0.7Rule LSTM_128for RNN_128  0.810811   \n",
       "55                EDCR           Confident 0.7Rule allfor RNN_128  0.810811   \n",
       "56                EDCR       Confident 0.7Rule allfor dumb_spikes  0.157658   \n",
       "57                EDCR   Confident 0.7Rule allfor dumb_non_spikes  0.819820   \n",
       "58                EDCR       Confident 0.8Rule LSTM_32for RNN_128  0.828829   \n",
       "59                EDCR     Confident 0.8Rule CNN_256_3for RNN_128  0.828829   \n",
       "60                EDCR      Confident 0.8Rule LSTM_256for RNN_128  0.833333   \n",
       "61                EDCR      Confident 0.8Rule CNN_64_3for RNN_128  0.828829   \n",
       "62                EDCR      Confident 0.8Rule LSTM_128for RNN_128  0.833333   \n",
       "63                EDCR           Confident 0.8Rule allfor RNN_128  0.833333   \n",
       "64                EDCR       Confident 0.8Rule allfor dumb_spikes  0.157658   \n",
       "65                EDCR   Confident 0.8Rule allfor dumb_non_spikes  0.837838   \n",
       "66                EDCR       Confident 0.9Rule LSTM_32for RNN_128  0.828829   \n",
       "67                EDCR     Confident 0.9Rule CNN_256_3for RNN_128  0.828829   \n",
       "68                EDCR      Confident 0.9Rule LSTM_256for RNN_128  0.828829   \n",
       "69                EDCR      Confident 0.9Rule CNN_64_3for RNN_128  0.828829   \n",
       "70                EDCR      Confident 0.9Rule LSTM_128for RNN_128  0.837838   \n",
       "71                EDCR           Confident 0.9Rule allfor RNN_128  0.837838   \n",
       "72                EDCR       Confident 0.9Rule allfor dumb_spikes  0.157658   \n",
       "73                EDCR   Confident 0.9Rule allfor dumb_non_spikes  0.837838   \n",
       "74                EDCR      Confident 0.95Rule LSTM_32for RNN_128  0.828829   \n",
       "75                EDCR    Confident 0.95Rule CNN_256_3for RNN_128  0.828829   \n",
       "76                EDCR     Confident 0.95Rule LSTM_256for RNN_128  0.828829   \n",
       "77                EDCR     Confident 0.95Rule CNN_64_3for RNN_128  0.828829   \n",
       "78                EDCR     Confident 0.95Rule LSTM_128for RNN_128  0.833333   \n",
       "79                EDCR          Confident 0.95Rule allfor RNN_128  0.833333   \n",
       "80                EDCR      Confident 0.95Rule allfor dumb_spikes  0.157658   \n",
       "81                EDCR  Confident 0.95Rule allfor dumb_non_spikes  0.842342   \n",
       "\n",
       "    Precision (0)  Recall (0)    F1 (0)  Precision (1)  Recall (1)    F1 (1)  \\\n",
       "0        0.860697    0.925134  0.891753       0.333333    0.200000  0.250000   \n",
       "1        0.875000    0.823529  0.848485       0.282609    0.371429  0.320988   \n",
       "2        0.724138    0.112299  0.194444       0.139896    0.771429  0.236842   \n",
       "3        0.862745    0.941176  0.900256       0.388889    0.200000  0.264151   \n",
       "4        0.838235    0.609626  0.705882       0.151163    0.371429  0.214876   \n",
       "5        0.832258    0.689840  0.754386       0.134328    0.257143  0.176471   \n",
       "6        0.771084    0.342246  0.474074       0.115108    0.457143  0.183908   \n",
       "7        0.850299    0.759358  0.802260       0.181818    0.285714  0.222222   \n",
       "8        0.851064    0.855615  0.853333       0.205882    0.200000  0.202899   \n",
       "9        0.828571    0.620321  0.709480       0.134146    0.314286  0.188034   \n",
       "10       0.846591    0.796791  0.820937       0.173913    0.228571  0.197531   \n",
       "11       0.848039    0.925134  0.884910       0.222222    0.114286  0.150943   \n",
       "12       0.860215    0.855615  0.857909       0.250000    0.257143  0.253521   \n",
       "13       0.845304    0.818182  0.831522       0.170732    0.200000  0.184211   \n",
       "14       0.841530    0.823529  0.832432       0.153846    0.171429  0.162162   \n",
       "15       0.845238    0.759358  0.800000       0.166667    0.257143  0.202247   \n",
       "16       0.750000    0.128342  0.219178       0.142105    0.771429  0.240000   \n",
       "17       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "18       0.840491    0.732620  0.782857       0.152542    0.257143  0.191489   \n",
       "19       0.808000    0.540107  0.647436       0.113402    0.314286  0.166667   \n",
       "20       0.834532    0.620321  0.711656       0.144578    0.342857  0.203390   \n",
       "21       0.800000    0.385027  0.519856       0.128788    0.485714  0.203593   \n",
       "22       0.832117    0.609626  0.703704       0.141176    0.342857  0.200000   \n",
       "23       0.849462    0.844920  0.847185       0.194444    0.200000  0.197183   \n",
       "24       0.815789    0.497326  0.617940       0.129630    0.400000  0.195804   \n",
       "25       0.860000    0.919786  0.888889       0.318182    0.200000  0.245614   \n",
       "26       0.846154    0.823529  0.834688       0.175000    0.200000  0.186667   \n",
       "27       0.854922    0.882353  0.868421       0.241379    0.200000  0.218750   \n",
       "28       0.825758    0.582888  0.683386       0.133333    0.342857  0.192000   \n",
       "29       0.848649    0.839572  0.844086       0.189189    0.200000  0.194444   \n",
       "30       0.797468    0.336898  0.473684       0.132867    0.542857  0.213483   \n",
       "31       0.861386    0.930481  0.894602       0.350000    0.200000  0.254545   \n",
       "32       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "33       0.842342    1.000000  0.914425       0.000000    0.000000  0.000000   \n",
       "34       0.861386    0.930481  0.894602       0.350000    0.200000  0.254545   \n",
       "35       0.861386    0.930481  0.894602       0.350000    0.200000  0.254545   \n",
       "36       0.860000    0.919786  0.888889       0.318182    0.200000  0.245614   \n",
       "37       0.860000    0.919786  0.888889       0.318182    0.200000  0.245614   \n",
       "38       0.874286    0.818182  0.845304       0.276596    0.371429  0.317073   \n",
       "39       0.869048    0.780749  0.822535       0.240741    0.371429  0.292135   \n",
       "40       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "41       0.869048    0.780749  0.822535       0.240741    0.371429  0.292135   \n",
       "42       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "43       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "44       0.864078    0.951872  0.905852       0.437500    0.200000  0.274510   \n",
       "45       0.855769    0.951872  0.901266       0.357143    0.142857  0.204082   \n",
       "46       0.857895    0.871658  0.864721       0.250000    0.228571  0.238806   \n",
       "47       0.857143    0.866310  0.861702       0.242424    0.228571  0.235294   \n",
       "48       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "49       0.857895    0.871658  0.864721       0.250000    0.228571  0.238806   \n",
       "50       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "51       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "52       0.860577    0.957219  0.906329       0.428571    0.171429  0.244898   \n",
       "53       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "54       0.860697    0.925134  0.891753       0.333333    0.200000  0.250000   \n",
       "55       0.860697    0.925134  0.891753       0.333333    0.200000  0.250000   \n",
       "56       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "57       0.862069    0.935829  0.897436       0.368421    0.200000  0.259259   \n",
       "58       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "59       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "60       0.860577    0.957219  0.906329       0.428571    0.171429  0.244898   \n",
       "61       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "62       0.864078    0.951872  0.905852       0.437500    0.200000  0.274510   \n",
       "63       0.864078    0.951872  0.905852       0.437500    0.200000  0.274510   \n",
       "64       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "65       0.861244    0.962567  0.909091       0.461538    0.171429  0.250000   \n",
       "66       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "67       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "68       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "69       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "70       0.864734    0.957219  0.908629       0.466667    0.200000  0.280000   \n",
       "71       0.864734    0.957219  0.908629       0.466667    0.200000  0.280000   \n",
       "72       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "73       0.854460    0.973262  0.910000       0.444444    0.114286  0.181818   \n",
       "74       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "75       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "76       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "77       0.856459    0.957219  0.904040       0.384615    0.142857  0.208333   \n",
       "78       0.860577    0.957219  0.906329       0.428571    0.171429  0.244898   \n",
       "79       0.860577    0.957219  0.906329       0.428571    0.171429  0.244898   \n",
       "80       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "81       0.851852    0.983957  0.913151       0.500000    0.085714  0.146341   \n",
       "\n",
       "    Prior  \n",
       "0    0.16  \n",
       "1    0.16  \n",
       "2    0.16  \n",
       "3    0.16  \n",
       "4    0.16  \n",
       "5    0.16  \n",
       "6    0.16  \n",
       "7    0.16  \n",
       "8    0.16  \n",
       "9    0.16  \n",
       "10   0.16  \n",
       "11   0.16  \n",
       "12   0.16  \n",
       "13   0.16  \n",
       "14   0.16  \n",
       "15   0.16  \n",
       "16   0.16  \n",
       "17   0.16  \n",
       "18   0.16  \n",
       "19   0.16  \n",
       "20   0.16  \n",
       "21   0.16  \n",
       "22   0.16  \n",
       "23   0.16  \n",
       "24   0.16  \n",
       "25   0.16  \n",
       "26   0.16  \n",
       "27   0.16  \n",
       "28   0.16  \n",
       "29   0.16  \n",
       "30   0.16  \n",
       "31   0.16  \n",
       "32   0.16  \n",
       "33   0.16  \n",
       "34   0.16  \n",
       "35   0.16  \n",
       "36   0.16  \n",
       "37   0.16  \n",
       "38   0.16  \n",
       "39   0.16  \n",
       "40   0.16  \n",
       "41   0.16  \n",
       "42   0.16  \n",
       "43   0.16  \n",
       "44   0.16  \n",
       "45   0.16  \n",
       "46   0.16  \n",
       "47   0.16  \n",
       "48   0.16  \n",
       "49   0.16  \n",
       "50   0.16  \n",
       "51   0.16  \n",
       "52   0.16  \n",
       "53   0.16  \n",
       "54   0.16  \n",
       "55   0.16  \n",
       "56   0.16  \n",
       "57   0.16  \n",
       "58   0.16  \n",
       "59   0.16  \n",
       "60   0.16  \n",
       "61   0.16  \n",
       "62   0.16  \n",
       "63   0.16  \n",
       "64   0.16  \n",
       "65   0.16  \n",
       "66   0.16  \n",
       "67   0.16  \n",
       "68   0.16  \n",
       "69   0.16  \n",
       "70   0.16  \n",
       "71   0.16  \n",
       "72   0.16  \n",
       "73   0.16  \n",
       "74   0.16  \n",
       "75   0.16  \n",
       "76   0.16  \n",
       "77   0.16  \n",
       "78   0.16  \n",
       "79   0.16  \n",
       "80   0.16  \n",
       "81   0.16  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = pd.read_csv(OG_RESULTS_PATH)\n",
    "og_df = og_df.drop('Unnamed: 0', axis=1)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "og_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
