{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMODITY = 'copper'\n",
    "METRIC = 'Recall'\n",
    "# ALGO = 'detection_correction'\n",
    "ALGO = 'correction'\n",
    "\n",
    "\n",
    "EDCR_RESULTS_PATH = f'{COMMODITY}/test/predictions/test_{METRIC}_{ALGO}'\n",
    "OG_RESULTS_PATH = f'{COMMODITY}/test/results_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_filename(filename):\n",
    "    parts = filename.split(\"Rule\")\n",
    "    epsilon = parts[0].split()[-1]\n",
    "    models_base = parts[1].split(\"for\")\n",
    "    models = models_base[0].strip()\n",
    "    base = models_base[1].split(\"_predictions\")[0].strip()\n",
    "    return base, models, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df):\n",
    "    y_true = df['True']\n",
    "    y_pred = df['Predicted']\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[0, 1])\n",
    "    prior = pd.read_csv(OG_RESULTS_PATH, nrows=1)['Prior'].iloc[0]\n",
    "    return accuracy, precision, recall, f1, prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(path):\n",
    "    all_results = []  \n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith('Confident') and filename.endswith(\"_predictions.csv\"):\n",
    "            base, models, confidence = extract_info_from_filename(filename)\n",
    "            df = pd.read_csv(os.path.join(path, filename))\n",
    "            accuracy, precision, recall, f1, prior = calculate_metrics(df)\n",
    "            row = {\n",
    "                'Base': base,\n",
    "                'Models': models,\n",
    "                'Confidence': confidence,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision (0)': precision[0],\n",
    "                'Recall (0)': recall[0],\n",
    "                'F1 (0)': f1[0],\n",
    "                'Precision (1)': precision[1],\n",
    "                'Recall (1)': recall[1],\n",
    "                'F1 (1)': f1[1],\n",
    "                'Prior': prior  \n",
    "            }\n",
    "            all_results.append(row)\n",
    "    \n",
    "    # Convert the list of results to a DataFrame\n",
    "    return pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manim\\LabV2\\ONR-Price-Prediction\\onr_price_prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results_df = process_files(EDCR_RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.159817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.112299</td>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.184685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>0.062176</td>\n",
       "      <td>0.162037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278884</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.184685</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>0.090452</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.155080</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>0.155080</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.342342</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.267380</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.159509</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.064171</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.158654</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.270492</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.247748</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.133690</td>\n",
       "      <td>0.230415</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.264317</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.463964</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.465241</td>\n",
       "      <td>0.593857</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.211921</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.454955</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.443850</td>\n",
       "      <td>0.578397</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.229299</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.261261</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.171123</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.143646</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.279279</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.219251</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.779279</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.877005</td>\n",
       "      <td>0.870027</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.850267</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.899743</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.887701</td>\n",
       "      <td>0.875989</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_256_7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNNA_32_5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>CNN_32_5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_128</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>RNN_32</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Base      Models Confidence  Accuracy  Precision (0)  Recall (0)  \\\n",
       "3   RNN_256  CNNA_256_7        0.1  0.157658       0.000000    0.000000   \n",
       "4   RNN_256   CNNA_32_5        0.1  0.157658       0.000000    0.000000   \n",
       "5   RNN_256    CNN_32_5        0.1  0.157658       0.000000    0.000000   \n",
       "6   RNN_256     RNN_128        0.1  0.157658       0.000000    0.000000   \n",
       "7   RNN_256      RNN_32        0.1  0.157658       0.000000    0.000000   \n",
       "11  RNN_256  CNNA_256_7        0.2  0.157658       0.000000    0.000000   \n",
       "12  RNN_256   CNNA_32_5        0.2  0.157658       0.500000    0.005348   \n",
       "13  RNN_256    CNN_32_5        0.2  0.171171       0.666667    0.032086   \n",
       "14  RNN_256     RNN_128        0.2  0.171171       1.000000    0.016043   \n",
       "15  RNN_256      RNN_32        0.2  0.157658       0.000000    0.000000   \n",
       "19  RNN_256  CNNA_256_7        0.3  0.157658       0.500000    0.005348   \n",
       "20  RNN_256   CNNA_32_5        0.3  0.171171       0.666667    0.032086   \n",
       "21  RNN_256    CNN_32_5        0.3  0.229730       0.807692    0.112299   \n",
       "22  RNN_256     RNN_128        0.3  0.189189       1.000000    0.037433   \n",
       "23  RNN_256      RNN_32        0.3  0.184685       1.000000    0.032086   \n",
       "27  RNN_256  CNNA_256_7        0.4  0.184685       0.750000    0.048128   \n",
       "28  RNN_256   CNNA_32_5        0.4  0.261261       0.828571    0.155080   \n",
       "29  RNN_256    CNN_32_5        0.4  0.342342       0.847458    0.267380   \n",
       "30  RNN_256     RNN_128        0.4  0.202703       0.857143    0.064171   \n",
       "31  RNN_256      RNN_32        0.4  0.198198       0.846154    0.058824   \n",
       "35  RNN_256  CNNA_256_7        0.5  0.247748       0.833333    0.133690   \n",
       "36  RNN_256   CNNA_32_5        0.5  0.463964       0.820755    0.465241   \n",
       "37  RNN_256    CNN_32_5        0.5  0.454955       0.830000    0.443850   \n",
       "38  RNN_256     RNN_128        0.5  0.261261       0.780488    0.171123   \n",
       "39  RNN_256      RNN_32        0.5  0.279279       0.745455    0.219251   \n",
       "43  RNN_256  CNNA_256_7        0.6  0.815315       0.857843    0.935829   \n",
       "44  RNN_256   CNNA_32_5        0.6  0.779279       0.863158    0.877005   \n",
       "45  RNN_256    CNN_32_5        0.6  0.756757       0.859459    0.850267   \n",
       "46  RNN_256     RNN_128        0.6  0.824324       0.866337    0.935829   \n",
       "47  RNN_256      RNN_32        0.6  0.788288       0.864583    0.887701   \n",
       "51  RNN_256  CNNA_256_7        0.7  0.815315       0.857843    0.935829   \n",
       "52  RNN_256   CNNA_32_5        0.7  0.810811       0.857143    0.930481   \n",
       "53  RNN_256    CNN_32_5        0.7  0.815315       0.857843    0.935829   \n",
       "54  RNN_256     RNN_128        0.7  0.815315       0.857843    0.935829   \n",
       "55  RNN_256      RNN_32        0.7  0.815315       0.857843    0.935829   \n",
       "59  RNN_256  CNNA_256_7        0.8  0.815315       0.857843    0.935829   \n",
       "60  RNN_256   CNNA_32_5        0.8  0.815315       0.857843    0.935829   \n",
       "61  RNN_256    CNN_32_5        0.8  0.815315       0.857843    0.935829   \n",
       "62  RNN_256     RNN_128        0.8  0.815315       0.857843    0.935829   \n",
       "63  RNN_256      RNN_32        0.8  0.815315       0.857843    0.935829   \n",
       "67  RNN_256  CNNA_256_7       0.95  0.815315       0.857843    0.935829   \n",
       "68  RNN_256   CNNA_32_5       0.95  0.815315       0.857843    0.935829   \n",
       "69  RNN_256    CNN_32_5       0.95  0.815315       0.857843    0.935829   \n",
       "70  RNN_256     RNN_128       0.95  0.815315       0.857843    0.935829   \n",
       "71  RNN_256      RNN_32       0.95  0.815315       0.857843    0.935829   \n",
       "75  RNN_256  CNNA_256_7        0.9  0.815315       0.857843    0.935829   \n",
       "76  RNN_256   CNNA_32_5        0.9  0.815315       0.857843    0.935829   \n",
       "77  RNN_256    CNN_32_5        0.9  0.815315       0.857843    0.935829   \n",
       "78  RNN_256     RNN_128        0.9  0.815315       0.857843    0.935829   \n",
       "79  RNN_256      RNN_32        0.9  0.815315       0.857843    0.935829   \n",
       "\n",
       "      F1 (0)  Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "3   0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "4   0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "5   0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "6   0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "7   0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "11  0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "12  0.010582       0.154545    0.971429  0.266667   0.16  \n",
       "13  0.061224       0.150235    0.914286  0.258065   0.16  \n",
       "14  0.031579       0.159817    1.000000  0.275591   0.16  \n",
       "15  0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "19  0.010582       0.154545    0.971429  0.266667   0.16  \n",
       "20  0.061224       0.150235    0.914286  0.258065   0.16  \n",
       "21  0.197183       0.153061    0.857143  0.259740   0.16  \n",
       "22  0.072165       0.162791    1.000000  0.280000   0.16  \n",
       "23  0.062176       0.162037    1.000000  0.278884   0.16  \n",
       "27  0.090452       0.152381    0.914286  0.261224   0.16  \n",
       "28  0.261261       0.155080    0.828571  0.261261   0.16  \n",
       "29  0.406504       0.159509    0.742857  0.262626   0.16  \n",
       "30  0.119403       0.158654    0.942857  0.271605   0.16  \n",
       "31  0.110000       0.157895    0.942857  0.270492   0.16  \n",
       "35  0.230415       0.156250    0.857143  0.264317   0.16  \n",
       "36  0.593857       0.137931    0.457143  0.211921   0.16  \n",
       "37  0.578397       0.147541    0.514286  0.229299   0.16  \n",
       "38  0.280702       0.143646    0.742857  0.240741   0.16  \n",
       "39  0.338843       0.125749    0.600000  0.207921   0.16  \n",
       "43  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "44  0.870027       0.281250    0.257143  0.268657   0.16  \n",
       "45  0.854839       0.243243    0.257143  0.250000   0.16  \n",
       "46  0.899743       0.400000    0.228571  0.290909   0.16  \n",
       "47  0.875989       0.300000    0.257143  0.276923   0.16  \n",
       "51  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "52  0.892308       0.315789    0.171429  0.222222   0.16  \n",
       "53  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "54  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "55  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "59  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "60  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "61  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "62  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "63  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "67  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "68  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "69  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "70  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "71  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "75  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "76  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "77  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "78  0.895141       0.333333    0.171429  0.226415   0.16  \n",
       "79  0.895141       0.333333    0.171429  0.226415   0.16  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_one = results_df[results_df['Models'] != 'all']\n",
    "# pd.set_option('display.max_rows', 200)\n",
    "results_df_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>128 layers</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.810198</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNN</td>\n",
       "      <td>256 units</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name      Params  Accuracy  Precision (0)  Recall (0)    F1 (0)  \\\n",
       "1   LSTM  128 layers  0.698198       0.861446    0.764706  0.810198   \n",
       "16   RNN   256 units  0.815315       0.857843    0.935829  0.895141   \n",
       "\n",
       "    Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "1        0.214286    0.342857  0.263736   0.16  \n",
       "16       0.333333    0.171429  0.226415   0.16  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(OG_RESULTS_PATH)\n",
    "df = df[(df['Name']=='RNN') & (df['Params'] == '256 units') | (df['Name']=='LSTM') & (df['Params'] == '128 layers')]\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.154206</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.265060</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.207207</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.074866</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.156098</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.725225</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.831956</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RNN_256</td>\n",
       "      <td>all</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.895141</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Base Models Confidence  Accuracy  Precision (0)  Recall (0)    F1 (0)  \\\n",
       "2   RNN_256    all        0.1  0.157658       0.000000    0.000000  0.000000   \n",
       "10  RNN_256    all        0.2  0.157658       0.000000    0.000000  0.000000   \n",
       "18  RNN_256    all        0.3  0.162162       1.000000    0.005348  0.010638   \n",
       "26  RNN_256    all        0.4  0.175676       0.750000    0.032086  0.061538   \n",
       "34  RNN_256    all        0.5  0.207207       0.823529    0.074866  0.137255   \n",
       "42  RNN_256    all        0.6  0.725225       0.857955    0.807487  0.831956   \n",
       "50  RNN_256    all        0.7  0.810811       0.857143    0.930481  0.892308   \n",
       "58  RNN_256    all        0.8  0.815315       0.857843    0.935829  0.895141   \n",
       "66  RNN_256    all       0.95  0.815315       0.857843    0.935829  0.895141   \n",
       "74  RNN_256    all        0.9  0.815315       0.857843    0.935829  0.895141   \n",
       "\n",
       "    Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "2        0.157658    1.000000  0.272374   0.16  \n",
       "10       0.157658    1.000000  0.272374   0.16  \n",
       "18       0.158371    1.000000  0.273438   0.16  \n",
       "26       0.154206    0.942857  0.265060   0.16  \n",
       "34       0.156098    0.914286  0.266667   0.16  \n",
       "42       0.217391    0.285714  0.246914   0.16  \n",
       "50       0.315789    0.171429  0.222222   0.16  \n",
       "58       0.333333    0.171429  0.226415   0.16  \n",
       "66       0.333333    0.171429  0.226415   0.16  \n",
       "74       0.333333    0.171429  0.226415   0.16  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_all = results_df[(results_df['Models'] == 'all') & (results_df['Base'] != \"dumb_spikes\") & (results_df['Base'] != \"dumb_non_spikes\")]\n",
    "results_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumb Model (Only Predicts Spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>dumb_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Base Models Confidence  Accuracy  Precision (0)  Recall (0)  \\\n",
       "1   dumb_spikes    all        0.1  0.157658            0.0         0.0   \n",
       "9   dumb_spikes    all        0.2  0.157658            0.0         0.0   \n",
       "17  dumb_spikes    all        0.3  0.157658            0.0         0.0   \n",
       "25  dumb_spikes    all        0.4  0.157658            0.0         0.0   \n",
       "33  dumb_spikes    all        0.5  0.157658            0.0         0.0   \n",
       "41  dumb_spikes    all        0.6  0.157658            0.0         0.0   \n",
       "49  dumb_spikes    all        0.7  0.157658            0.0         0.0   \n",
       "57  dumb_spikes    all        0.8  0.157658            0.0         0.0   \n",
       "65  dumb_spikes    all       0.95  0.157658            0.0         0.0   \n",
       "73  dumb_spikes    all        0.9  0.157658            0.0         0.0   \n",
       "\n",
       "    F1 (0)  Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "1      0.0       0.157658         1.0  0.272374   0.16  \n",
       "9      0.0       0.157658         1.0  0.272374   0.16  \n",
       "17     0.0       0.157658         1.0  0.272374   0.16  \n",
       "25     0.0       0.157658         1.0  0.272374   0.16  \n",
       "33     0.0       0.157658         1.0  0.272374   0.16  \n",
       "41     0.0       0.157658         1.0  0.272374   0.16  \n",
       "49     0.0       0.157658         1.0  0.272374   0.16  \n",
       "57     0.0       0.157658         1.0  0.272374   0.16  \n",
       "65     0.0       0.157658         1.0  0.272374   0.16  \n",
       "73     0.0       0.157658         1.0  0.272374   0.16  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_all = results_df[(results_df['Models'] == 'all') & (results_df['Base'] == \"dumb_spikes\")]\n",
    "results_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumb Model (Only Predicts Non-Spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Models</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.184685</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.042781</td>\n",
       "      <td>0.081218</td>\n",
       "      <td>0.155660</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.267206</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.096257</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.834225</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.842593</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>dumb_non_spikes</td>\n",
       "      <td>all</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Base Models Confidence  Accuracy  Precision (0)  Recall (0)  \\\n",
       "0   dumb_non_spikes    all        0.1  0.157658       0.000000    0.000000   \n",
       "8   dumb_non_spikes    all        0.2  0.157658       0.000000    0.000000   \n",
       "16  dumb_non_spikes    all        0.3  0.162162       1.000000    0.005348   \n",
       "24  dumb_non_spikes    all        0.4  0.184685       0.800000    0.042781   \n",
       "32  dumb_non_spikes    all        0.5  0.216216       0.782609    0.096257   \n",
       "40  dumb_non_spikes    all        0.6  0.738739       0.852459    0.834225   \n",
       "48  dumb_non_spikes    all        0.7  0.824324       0.842593    0.973262   \n",
       "56  dumb_non_spikes    all        0.8  0.842342       0.842342    1.000000   \n",
       "64  dumb_non_spikes    all       0.95  0.842342       0.842342    1.000000   \n",
       "72  dumb_non_spikes    all        0.9  0.842342       0.842342    1.000000   \n",
       "\n",
       "      F1 (0)  Precision (1)  Recall (1)    F1 (1)  Prior  \n",
       "0   0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "8   0.000000       0.157658    1.000000  0.272374   0.16  \n",
       "16  0.010638       0.158371    1.000000  0.273438   0.16  \n",
       "24  0.081218       0.155660    0.942857  0.267206   0.16  \n",
       "32  0.171429       0.150754    0.857143  0.256410   0.16  \n",
       "40  0.843243       0.205128    0.228571  0.216216   0.16  \n",
       "48  0.903226       0.166667    0.028571  0.048780   0.16  \n",
       "56  0.914425       0.000000    0.000000  0.000000   0.16  \n",
       "64  0.914425       0.000000    0.000000  0.000000   0.16  \n",
       "72  0.914425       0.000000    0.000000  0.000000   0.16  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_all = results_df[(results_df['Models'] == 'all') & (results_df['Base'] == \"dumb_non_spikes\")]\n",
    "results_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1 (0)</th>\n",
       "      <th>Precision (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1 (1)</th>\n",
       "      <th>Prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>256 layers</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.898396</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>128 layers</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.810198</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>64 layers</td>\n",
       "      <td>0.495495</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>32 layers</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.838150</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN with Attention</td>\n",
       "      <td>32 filters, kernel size 7</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>0.812325</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor RNN_256</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor dumb_spikes</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272374</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor dumb_spikes</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>EDCR</td>\n",
       "      <td>Confident 0.95Rule allfor dumb_non_spikes</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                                     Params  Accuracy  \\\n",
       "0                  LSTM                                 256 layers  0.797297   \n",
       "1                  LSTM                                 128 layers  0.698198   \n",
       "2                  LSTM                                  64 layers  0.495495   \n",
       "3                  LSTM                                  32 layers  0.684685   \n",
       "4    CNN with Attention                  32 filters, kernel size 7  0.698198   \n",
       "..                  ...                                        ...       ...   \n",
       "509                EDCR          Confident 0.95Rule allfor RNN_256  0.842342   \n",
       "510                EDCR      Confident 0.95Rule allfor dumb_spikes  0.157658   \n",
       "511                EDCR      Confident 0.95Rule allfor dumb_spikes  0.842342   \n",
       "512                EDCR  Confident 0.95Rule allfor dumb_non_spikes  0.842342   \n",
       "513                EDCR  Confident 0.95Rule allfor dumb_non_spikes  0.842342   \n",
       "\n",
       "     Precision (0)  Recall (0)    F1 (0)  Precision (1)  Recall (1)    F1 (1)  \\\n",
       "0         0.865979    0.898396  0.881890       0.321429    0.257143  0.285714   \n",
       "1         0.861446    0.764706  0.810198       0.214286    0.342857  0.263736   \n",
       "2         0.804878    0.529412  0.638710       0.111111    0.314286  0.164179   \n",
       "3         0.838150    0.775401  0.805556       0.142857    0.200000  0.166667   \n",
       "4         0.852941    0.775401  0.812325       0.192308    0.285714  0.229885   \n",
       "..             ...         ...       ...            ...         ...       ...   \n",
       "509       0.845455    0.994652  0.914005       0.500000    0.028571  0.054054   \n",
       "510       0.000000    0.000000  0.000000       0.157658    1.000000  0.272374   \n",
       "511       0.845455    0.994652  0.914005       0.500000    0.028571  0.054054   \n",
       "512       0.845455    0.994652  0.914005       0.500000    0.028571  0.054054   \n",
       "513       0.845455    0.994652  0.914005       0.500000    0.028571  0.054054   \n",
       "\n",
       "     Prior  \n",
       "0     0.16  \n",
       "1     0.16  \n",
       "2     0.16  \n",
       "3     0.16  \n",
       "4     0.16  \n",
       "..     ...  \n",
       "509   0.16  \n",
       "510   0.16  \n",
       "511   0.16  \n",
       "512   0.16  \n",
       "513   0.16  \n",
       "\n",
       "[514 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = pd.read_csv(OG_RESULTS_PATH)\n",
    "og_df = og_df.drop('Unnamed: 0', axis=1)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "og_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
