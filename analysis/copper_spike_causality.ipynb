{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install scikit-learn\n",
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMODITY = 'copper'\n",
    "\n",
    "DATE_COLUMN = 'Date'\n",
    "VALUE_COLUMN = 'Value'  \n",
    "QUANTITY_COLUMN = 'Std. Quantity (KG)'\n",
    "UNIT_RATE_COLUMN = 'Std. Unit Rate ($/KG)'\n",
    "BRENT_OIL_COLUMN = 'Brent Oil Value'\n",
    "WTI_OIL_COLUMN = 'WTI Oil Value'\n",
    "\n",
    "VALUE_SPIKES_COLUMN = 'Value Spikes'  \n",
    "QUANTITY_SPIKES_COLUMN = 'Std. Quantity (KG) Spikes'\n",
    "UNIT_RATE_SPIKES_COLUMN = 'Std. Unit Rate ($/KG) Spikes'\n",
    "BRENT_OIL_SPIKES_COLUMN = 'Brent Oil Value'\n",
    "WTI_OIL_SPIKES_COLUMN = 'WTI Oil Value'\n",
    "\n",
    "ORIGIN_COUNTRY_COLUMN = 'Country of Origin'\n",
    "DEST_COUNTRY_COLUMN = 'Country of Destination'\n",
    "\n",
    "PETROL_FILE_PATH = '../volza/petroleum/petrol_crude_oil_spot_price.csv'\n",
    "VOLZA_FILE_PATH = f'../volza/{COMMODITY}/{COMMODITY}.csv'\n",
    "PRICE_FILE_PATH = f\"../volza/{COMMODITY}/{COMMODITY}_prices.csv\"\n",
    "\n",
    "SPIKES_THRESHOLD = 2\n",
    "SPIKES_WINDOW_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep rows where we have usable quantity units (kg, ton) and standardizing it. For VOLZA only.\n",
    "def convert_to_pound(df, quantity_col='Std. Quantity', unit_col='Std. Unit'):\n",
    "    converstion_factors = {\n",
    "        'TON': 907.185 * 2.20462,  \n",
    "        'TNE': 1000 * 2.20462,     \n",
    "        'KGS': 2.20462,            \n",
    "        'Kgs': 2.20462,\n",
    "    }\n",
    "\n",
    "    df_filtered = df[df[unit_col].isin(converstion_factors.keys())]\n",
    "\n",
    "    def convert(row):\n",
    "        unit = row[unit_col]\n",
    "        quantity = row[quantity_col]\n",
    "        return quantity * converstion_factors.get(unit,1)\n",
    "    \n",
    "    df_filtered = df_filtered[df_filtered[VALUE_COLUMN] != 0]\n",
    "    df_filtered[QUANTITY_COLUMN] = df_filtered.apply(convert, axis=1)\n",
    "    df_filtered = df_filtered[df_filtered[QUANTITY_COLUMN] != 0]\n",
    "\n",
    "    df_filtered[UNIT_RATE_COLUMN] = df_filtered[VALUE_COLUMN] / df_filtered[QUANTITY_COLUMN]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Date</th>\n",
       "      <th>HS Code</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Consignee</th>\n",
       "      <th>Notify Party Name</th>\n",
       "      <th>Shipper</th>\n",
       "      <th>Std. Quantity</th>\n",
       "      <th>Std. Unit</th>\n",
       "      <th>Standard Unit Rate INR</th>\n",
       "      <th>...</th>\n",
       "      <th>Freight Term</th>\n",
       "      <th>Marks Number</th>\n",
       "      <th>HS Product Description</th>\n",
       "      <th>Gross Weight</th>\n",
       "      <th>Consignee Address</th>\n",
       "      <th>Shipper Address</th>\n",
       "      <th>Notify Party Address</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Std. Quantity (KG)</th>\n",
       "      <th>Std. Unit Rate ($/KG)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>74020000</td>\n",
       "      <td>COPPER, UNREFINED; COPPER ANODES FOR ELECTROLY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "      <td>TON</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lithuania T1  Import</td>\n",
       "      <td>13.999987</td>\n",
       "      <td>5.537862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>74020000</td>\n",
       "      <td>COPPER, UNREFINED; COPPER ANODES FOR ELECTROLY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021</td>\n",
       "      <td>TON</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portugal T1  Import</td>\n",
       "      <td>41.999962</td>\n",
       "      <td>65.516488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>74020000</td>\n",
       "      <td>COPPER, UNREFINED; COPPER ANODES FOR ELECTROLY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>TON</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France T1  Import</td>\n",
       "      <td>1.999998</td>\n",
       "      <td>10.110009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       Date   HS Code                                Product Description  \\\n",
       "0  1 2019-04-01  74020000  COPPER, UNREFINED; COPPER ANODES FOR ELECTROLY...   \n",
       "1  2 2019-04-01  74020000  COPPER, UNREFINED; COPPER ANODES FOR ELECTROLY...   \n",
       "2  3 2019-04-01  74020000  COPPER, UNREFINED; COPPER ANODES FOR ELECTROLY...   \n",
       "\n",
       "  Consignee Notify Party Name Shipper  Std. Quantity Std. Unit  \\\n",
       "0       NaN               NaN     NaN          0.007       TON   \n",
       "1       NaN               NaN     NaN          0.021       TON   \n",
       "2       NaN               NaN     NaN          0.001       TON   \n",
       "\n",
       "  Standard Unit Rate INR  ...  Freight Term Marks Number  \\\n",
       "0                      -  ...             -            -   \n",
       "1                      -  ...             -            -   \n",
       "2                      -  ...             -            -   \n",
       "\n",
       "  HS Product Description Gross Weight  Consignee Address Shipper Address  \\\n",
       "0                    NaN          0.0                NaN             NaN   \n",
       "1                    NaN          0.0                NaN             NaN   \n",
       "2                    NaN          0.0                NaN             NaN   \n",
       "\n",
       "  Notify Party Address          Country Name Std. Quantity (KG)  \\\n",
       "0                  NaN  Lithuania T1  Import          13.999987   \n",
       "1                  NaN   Portugal T1  Import          41.999962   \n",
       "2                  NaN     France T1  Import           1.999998   \n",
       "\n",
       "  Std. Unit Rate ($/KG)  \n",
       "0              5.537862  \n",
       "1             65.516488  \n",
       "2             10.110009  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#Formatting the date and price for Volza data\n",
    "volza_pd = pd.read_csv(VOLZA_FILE_PATH)\n",
    "volza_pd = volza_pd[(volza_pd[\"Country of Origin\"].notnull()) & (volza_pd[\"Country of Destination\"].notnull())]\n",
    "volza_pd = volza_pd.rename(columns={'Unnamed: 0': 'ID'})\n",
    "volza_pd['Date'] = volza_pd['Date'].apply(lambda x: x.split(' ')[0])\n",
    "volza_pd['Date'] = pd.to_datetime(volza_pd['Date'], errors='raise', format='%Y-%m-%d')\n",
    "volza_pd = convert_to_pound(volza_pd)\n",
    "volza_pd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>3.8055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>3.8210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>3.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>3.8335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>3.8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2.6605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2.6515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2.5705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2.6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Price\n",
       "0    2022-12-30  3.8055\n",
       "1    2022-12-29  3.8210\n",
       "2    2022-12-28  3.8320\n",
       "3    2022-12-27  3.8335\n",
       "4    2022-12-23  3.8030\n",
       "...         ...     ...\n",
       "1003 2019-01-08  2.6605\n",
       "1004 2019-01-07  2.6410\n",
       "1005 2019-01-04  2.6515\n",
       "1006 2019-01-03  2.5705\n",
       "1007 2019-01-02  2.6250\n",
       "\n",
       "[1008 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing the price data\n",
    "prices_pd = pd.read_csv(PRICE_FILE_PATH)\n",
    "prices_pd['Date'] = prices_pd['Date'].apply(lambda x: datetime.strptime(x, \"%b %d, %Y\").strftime(\"%Y-%m-%d\"))\n",
    "prices_pd['Date'] = pd.to_datetime(prices_pd['Date'], errors='raise', format='%Y-%m-%d')\n",
    "prices_pd['Price'] = prices_pd['Price'].astype(float)  \n",
    "prices_pd = prices_pd[['Date', 'Price']]\n",
    "prices_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate volza data by day\n",
    "date_wise_volza = volza_pd.groupby(\"Date\")[[VALUE_COLUMN,QUANTITY_COLUMN,'Gross Weight']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Std. Quantity (KG)</th>\n",
       "      <th>Gross Weight</th>\n",
       "      <th>Std. Unit Rate ($/KG)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>3.580679e+08</td>\n",
       "      <td>1.115013e+08</td>\n",
       "      <td>512426.9</td>\n",
       "      <td>23.234310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>2.899774e+07</td>\n",
       "      <td>9.930702e+06</td>\n",
       "      <td>4507752.0</td>\n",
       "      <td>2.912255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>1.652543e+07</td>\n",
       "      <td>5.351697e+06</td>\n",
       "      <td>2428782.0</td>\n",
       "      <td>4.118381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>1.381037e+05</td>\n",
       "      <td>4.362061e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.563629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06</th>\n",
       "      <td>1.854971e+07</td>\n",
       "      <td>6.670174e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1790.400393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>3.660210e+07</td>\n",
       "      <td>1.011938e+07</td>\n",
       "      <td>2301364.0</td>\n",
       "      <td>3.447410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>9.597299e+06</td>\n",
       "      <td>5.367289e+06</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>6.130818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>1.148950e+08</td>\n",
       "      <td>5.010989e+06</td>\n",
       "      <td>360.0</td>\n",
       "      <td>168.297919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>1.290664e+07</td>\n",
       "      <td>3.340804e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.758166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>3.461623e+08</td>\n",
       "      <td>7.181358e+07</td>\n",
       "      <td>962244.0</td>\n",
       "      <td>19.809922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Value  Std. Quantity (KG)  Gross Weight  \\\n",
       "Date                                                         \n",
       "2019-01-01  3.580679e+08        1.115013e+08      512426.9   \n",
       "2019-01-02  2.899774e+07        9.930702e+06     4507752.0   \n",
       "2019-01-03  1.652543e+07        5.351697e+06     2428782.0   \n",
       "2019-01-04  1.381037e+05        4.362061e+04           0.0   \n",
       "2019-01-06  1.854971e+07        6.670174e+06           0.0   \n",
       "...                  ...                 ...           ...   \n",
       "2022-12-28  3.660210e+07        1.011938e+07     2301364.0   \n",
       "2022-12-29  9.597299e+06        5.367289e+06        2415.6   \n",
       "2022-12-30  1.148950e+08        5.010989e+06         360.0   \n",
       "2022-12-31  1.290664e+07        3.340804e+06           0.0   \n",
       "2023-01-01  3.461623e+08        7.181358e+07      962244.0   \n",
       "\n",
       "            Std. Unit Rate ($/KG)  \n",
       "Date                               \n",
       "2019-01-01              23.234310  \n",
       "2019-01-02               2.912255  \n",
       "2019-01-03               4.118381  \n",
       "2019-01-04               2.563629  \n",
       "2019-01-06            1790.400393  \n",
       "...                           ...  \n",
       "2022-12-28               3.447410  \n",
       "2022-12-29               6.130818  \n",
       "2022-12-30             168.297919  \n",
       "2022-12-31               3.758166  \n",
       "2023-01-01              19.809922  \n",
       "\n",
       "[1238 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg of Commodity Price in Volza\n",
    "avg_price_volza = volza_pd.groupby('Date')[UNIT_RATE_COLUMN].mean()\n",
    "date_wise_volza = date_wise_volza.join(avg_price_volza, how='left')\n",
    "date_wise_volza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_5384\\273638861.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  brent_df.rename(columns={'Value':'Brent Oil Value'}, inplace=True)\n",
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_5384\\273638861.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wti_df.rename(columns={'Value':'WTI Oil Value'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Petroleum data prep\n",
    "petrol_df = pd.read_csv(PETROL_FILE_PATH, delimiter=';', on_bad_lines='warn')\n",
    "petrol_df['Date'] = pd.to_datetime(petrol_df['Date'])\n",
    "\n",
    "# Split based on types of oil\n",
    "brent_df = petrol_df[petrol_df['product-name']=='UK Brent Crude Oil']\n",
    "wti_df = petrol_df[petrol_df['product-name']=='WTI Crude Oil']\n",
    "\n",
    "brent_df.rename(columns={'Value':'Brent Oil Value'}, inplace=True)\n",
    "wti_df.rename(columns={'Value':'WTI Oil Value'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_5384\\2311230880.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aggregated_df = date_wise_volza.join(prices_pd, how=\"left\").fillna(method='ffill')\n",
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_5384\\2311230880.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aggregated_df = aggregated_df.merge(brent_df[[DATE_COLUMN, BRENT_OIL_COLUMN]], on='Date', how='left').fillna(method='ffill')\n",
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_5384\\2311230880.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aggregated_df = aggregated_df.merge(wti_df[[DATE_COLUMN, WTI_OIL_COLUMN]], on='Date', how='left').fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Combining dataframes\n",
    "prices_pd = prices_pd.set_index('Date')\n",
    "aggregated_df = date_wise_volza.join(prices_pd, how=\"left\").fillna(method='ffill')\n",
    "aggregated_df = aggregated_df.merge(brent_df[[DATE_COLUMN, BRENT_OIL_COLUMN]], on='Date', how='left').fillna(method='ffill')\n",
    "aggregated_df = aggregated_df.merge(wti_df[[DATE_COLUMN, WTI_OIL_COLUMN]], on='Date', how='left').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPIKES : NON SPIKES = \n",
      "spikes\n",
      "0    1102\n",
      "1     136\n",
      "Name: count, dtype: int64\n",
      "PERCENT OF SPIKES 0.1098546042003231\n"
     ]
    }
   ],
   "source": [
    "def detect_spikes(df, column):\n",
    "    ## Detecting spikes\n",
    "    moving_avg = df[column].rolling(window=SPIKES_WINDOW_SIZE).mean()\n",
    "    std_dev = df[column].rolling(window=SPIKES_WINDOW_SIZE).std()\n",
    "\n",
    "    # Set a threshold to identify spikes\n",
    "    return (abs(aggregated_df[column] - moving_avg) > SPIKES_THRESHOLD * std_dev).astype(int)\n",
    "\n",
    "aggregated_df['spikes'] = detect_spikes(aggregated_df, 'Price')\n",
    "print(\"SPIKES : NON SPIKES = \")\n",
    "print(aggregated_df['spikes'].value_counts())\n",
    "print(\"PERCENT OF SPIKES\", aggregated_df['spikes'].value_counts()[1]/len(aggregated_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Detect spikes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df[VALUE_SPIKES_COLUMN] = detect_spikes(aggregated_df, VALUE_COLUMN)\n",
    "aggregated_df[QUANTITY_SPIKES_COLUMN] = detect_spikes(aggregated_df, QUANTITY_COLUMN)\n",
    "aggregated_df[UNIT_RATE_SPIKES_COLUMN] = detect_spikes(aggregated_df, UNIT_RATE_COLUMN)\n",
    "aggregated_df[WTI_OIL_SPIKES_COLUMN] = detect_spikes(aggregated_df, WTI_OIL_COLUMN)\n",
    "aggregated_df[BRENT_OIL_SPIKES_COLUMN] = detect_spikes(aggregated_df, BRENT_OIL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>Std. Quantity (KG)</th>\n",
       "      <th>Gross Weight</th>\n",
       "      <th>Std. Unit Rate ($/KG)</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brent Oil Value</th>\n",
       "      <th>WTI Oil Value</th>\n",
       "      <th>spikes</th>\n",
       "      <th>Value Spikes</th>\n",
       "      <th>Std. Quantity (KG) Spikes</th>\n",
       "      <th>Std. Unit Rate ($/KG) Spikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3.580679e+08</td>\n",
       "      <td>1.115013e+08</td>\n",
       "      <td>512426.9</td>\n",
       "      <td>23.234310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2.899774e+07</td>\n",
       "      <td>9.930702e+06</td>\n",
       "      <td>4507752.0</td>\n",
       "      <td>2.912255</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>1.652543e+07</td>\n",
       "      <td>5.351697e+06</td>\n",
       "      <td>2428782.0</td>\n",
       "      <td>4.118381</td>\n",
       "      <td>2.5705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>1.381037e+05</td>\n",
       "      <td>4.362061e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.563629</td>\n",
       "      <td>2.6515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>1.854971e+07</td>\n",
       "      <td>6.670174e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1790.400393</td>\n",
       "      <td>2.6515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>3.660210e+07</td>\n",
       "      <td>1.011938e+07</td>\n",
       "      <td>2301364.0</td>\n",
       "      <td>3.447410</td>\n",
       "      <td>3.8320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>9.597299e+06</td>\n",
       "      <td>5.367289e+06</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>6.130818</td>\n",
       "      <td>3.8210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>1.148950e+08</td>\n",
       "      <td>5.010989e+06</td>\n",
       "      <td>360.0</td>\n",
       "      <td>168.297919</td>\n",
       "      <td>3.8055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>1.290664e+07</td>\n",
       "      <td>3.340804e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.758166</td>\n",
       "      <td>3.8055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>3.461623e+08</td>\n",
       "      <td>7.181358e+07</td>\n",
       "      <td>962244.0</td>\n",
       "      <td>19.809922</td>\n",
       "      <td>3.8055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Value  Std. Quantity (KG)  Gross Weight  \\\n",
       "0    2019-01-01  3.580679e+08        1.115013e+08      512426.9   \n",
       "1    2019-01-02  2.899774e+07        9.930702e+06     4507752.0   \n",
       "2    2019-01-03  1.652543e+07        5.351697e+06     2428782.0   \n",
       "3    2019-01-04  1.381037e+05        4.362061e+04           0.0   \n",
       "4    2019-01-06  1.854971e+07        6.670174e+06           0.0   \n",
       "...         ...           ...                 ...           ...   \n",
       "1233 2022-12-28  3.660210e+07        1.011938e+07     2301364.0   \n",
       "1234 2022-12-29  9.597299e+06        5.367289e+06        2415.6   \n",
       "1235 2022-12-30  1.148950e+08        5.010989e+06         360.0   \n",
       "1236 2022-12-31  1.290664e+07        3.340804e+06           0.0   \n",
       "1237 2023-01-01  3.461623e+08        7.181358e+07      962244.0   \n",
       "\n",
       "      Std. Unit Rate ($/KG)   Price  Brent Oil Value  WTI Oil Value  spikes  \\\n",
       "0                 23.234310     NaN                0              0       0   \n",
       "1                  2.912255  2.6250                0              0       0   \n",
       "2                  4.118381  2.5705                0              0       0   \n",
       "3                  2.563629  2.6515                0              0       0   \n",
       "4               1790.400393  2.6515                0              0       0   \n",
       "...                     ...     ...              ...            ...     ...   \n",
       "1233               3.447410  3.8320                0              0       0   \n",
       "1234               6.130818  3.8210                0              0       0   \n",
       "1235             168.297919  3.8055                0              0       0   \n",
       "1236               3.758166  3.8055                0              0       0   \n",
       "1237              19.809922  3.8055                0              0       0   \n",
       "\n",
       "      Value Spikes  Std. Quantity (KG) Spikes  Std. Unit Rate ($/KG) Spikes  \n",
       "0                0                          0                             0  \n",
       "1                0                          0                             0  \n",
       "2                0                          0                             0  \n",
       "3                0                          0                             0  \n",
       "4                0                          0                             0  \n",
       "...            ...                        ...                           ...  \n",
       "1233             0                          0                             0  \n",
       "1234             0                          0                             0  \n",
       "1235             1                          0                             1  \n",
       "1236             0                          0                             0  \n",
       "1237             1                          1                             0  \n",
       "\n",
       "[1238 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove date 2020-01-01\n",
    "aggregated_df = aggregated_df[aggregated_df.index != '2020-01-01']\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Causality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_5384\\424184215.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aggregated_df_spikes['VALID'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>support</th>\n",
       "      <th>causality</th>\n",
       "      <th>rel</th>\n",
       "      <th>conditional_probability</th>\n",
       "      <th>prior</th>\n",
       "      <th>conditional - prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brent Oil Value</td>\n",
       "      <td>136</td>\n",
       "      <td>0.069324</td>\n",
       "      <td>WTI Oil Value,Value Spikes,Std. Quantity (KG) ...</td>\n",
       "      <td>0.169118</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.059263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WTI Oil Value</td>\n",
       "      <td>118</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>Brent Oil Value,Value Spikes,Std. Quantity (KG...</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.068111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Value Spikes</td>\n",
       "      <td>69</td>\n",
       "      <td>-0.013655</td>\n",
       "      <td>Brent Oil Value,WTI Oil Value,Std. Quantity (K...</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.049566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Std. Quantity (KG) Spikes</td>\n",
       "      <td>66</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>Brent Oil Value,WTI Oil Value,Value Spikes</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.041661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Std. Unit Rate ($/KG) Spikes</td>\n",
       "      <td>77</td>\n",
       "      <td>n/a</td>\n",
       "      <td></td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>-0.005959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  support causality  \\\n",
       "0               Brent Oil Value      136  0.069324   \n",
       "0                 WTI Oil Value      118  0.009189   \n",
       "0                  Value Spikes       69 -0.013655   \n",
       "0     Std. Quantity (KG) Spikes       66  0.039467   \n",
       "0  Std. Unit Rate ($/KG) Spikes       77       n/a   \n",
       "\n",
       "                                                 rel  conditional_probability  \\\n",
       "0  WTI Oil Value,Value Spikes,Std. Quantity (KG) ...                 0.169118   \n",
       "0  Brent Oil Value,Value Spikes,Std. Quantity (KG...                 0.177966   \n",
       "0  Brent Oil Value,WTI Oil Value,Std. Quantity (K...                 0.159420   \n",
       "0         Brent Oil Value,WTI Oil Value,Value Spikes                 0.151515   \n",
       "0                                                                    0.103896   \n",
       "\n",
       "      prior  conditional - prior  \n",
       "0  0.109855             0.059263  \n",
       "0  0.109855             0.068111  \n",
       "0  0.109855             0.049566  \n",
       "0  0.109855             0.041661  \n",
       "0  0.109855            -0.005959  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "class Causality:\n",
    "    @staticmethod\n",
    "    def causality_wrapper(input_df, VALID_COLUMN, EFFECT_COLUMN):\n",
    "        def negation(column):\n",
    "            # negation -- \n",
    "            # OUTPUT: returns a column of 0s and 1s of the negation of [column]. 1s are flipped to 0 and vice versa\n",
    "            # INPUT: [column] should be a column of 0s and 1s\n",
    "            return 1 - column\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def conjunction(column_1, column_2):\n",
    "            # conjunction -- \n",
    "            # output: returns a column of 0s and 1s of the conjunction between [column_1] and [column_2].\n",
    "            # INPUT: [column_1] and [column_2] should be columns of 0s and 1s\n",
    "            return column_1 * column_2\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def disjunction(column_1, column_2):\n",
    "            # disjunction -- \n",
    "            # OUTPUT: returns a column of 0s and 1s of the disjunction between [column_1] and [column_2].\n",
    "            # INPUT: [column_1] and [column_2] should be columns of 0s and 1s\n",
    "            return column_1 | column_2\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def conditional_probability(occurence_column, condition_column):\n",
    "            # conditional_probability -- \n",
    "            # OUTPUT: returns a number which represents the conditional probability p(occurence | condition)\n",
    "            # INPUT: [occurence_column] and [condition_column] should be columns of 0s and 1s\n",
    "            if condition_column.sum() == 0: return 0\n",
    "            return conjunction(occurence_column, condition_column).sum() / condition_column.sum()\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def prior(data):\n",
    "            # prior -- \n",
    "            # OUTPUT: returns a number which represents the prior\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN] and [VALID_COLUMN].\n",
    "            # TODO : Possible optimizations can be made where we cache the result instead of calling this expensive operation again and again\n",
    "            return conditional_probability(data[EFFECT_COLUMN], data[VALID_COLUMN])\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def is_prima_facie(data, column_name):\n",
    "            # is_prima_facie -- \n",
    "            # OUTPUT: returns a boolean which determines whether the column indicated by [column_name] is a prima facie\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN] and [VALID_COLUMN].\n",
    "            # INPUT: [column_name] should be a valid column in [data]\n",
    "            # INPUT: The [CORRECT_COLUMN] and [VALID_COLUMN] columns should be columns of 0s and 1s \n",
    "            return conditional_probability(data[EFFECT_COLUMN], data[column_name]) - prior(data) > 0\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def is_cooccur(column_1, column_2):\n",
    "            # is_cooccur -- \n",
    "            # OUTPUT: returns a boolean based on if there is at least one row where both [column_1] and [column_2] is equal to 1\n",
    "            # INPUT: [column_1] and [column_2] should both be columns of 0s and 1s\n",
    "            return conjunction(column_1, column_2).sum() > 0\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "            \n",
    "        def rel(data, column_name):\n",
    "            # rel -- \n",
    "            # OUTPUT: returns a list of the names of other columns which cooccur with [column_name] and are prima facie\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN] and [VALID_COLUMN].\n",
    "            # INPUT: [column_name] should be a valid column in [data]\n",
    "            # INPUT: The [CORRECT_COLUMN] and [VALID_COLUMN] columns should be columns of 0s and 1s \n",
    "            \n",
    "            # # If it is not a prima facie cause, we don't bother to find its rel\n",
    "            if not is_prima_facie(data,column_name): return[]\n",
    "                \n",
    "            if column_name in [VALID_COLUMN, EFFECT_COLUMN]: return []\n",
    "            \n",
    "            name_list = []\n",
    "            for potential_cause in data.columns:\n",
    "                # Make sure we are not including the [CORRECT_COLUMN] and [VALID_COLUMN] as part of rel\n",
    "                if potential_cause in [EFFECT_COLUMN, VALID_COLUMN, column_name]: continue\n",
    "\n",
    "                # if is_same_category(potential_cause, column_name): continue\n",
    "\n",
    "                if is_cooccur(data[column_name], data[potential_cause]) and is_prima_facie(data, potential_cause):\n",
    "                    name_list.append(potential_cause)\n",
    "            return name_list\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def calculate_causality(data, column_name):\n",
    "            # calculate_causality -- \n",
    "            # OUTPUT: returns a number which represents the causality value of the column indicated by [column_name]\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN].\n",
    "            # INPUT: [column_name] should be a valid column in [data]\n",
    "            # INPUT: The [CORRECT_COLUMN] and [VALID_COLUMN] columns should be columns of 0s and 1s \n",
    "\n",
    "            # If it's not a prima facie cause, we don't bother to calculate its causality value\n",
    "            if not is_prima_facie(data, column_name):\n",
    "                return \"n/a\"\n",
    "\n",
    "            relateds = rel(data, column_name)\n",
    "            total_probability = 0\n",
    "            for related in relateds:\n",
    "                conj = conjunction(data[column_name], data[related])\n",
    "                negj = conjunction(negation(data[column_name]), data[related])\n",
    "\n",
    "                k = data[column_name].sum() / len(data)\n",
    "                conj = conditional_probability(data[EFFECT_COLUMN], conj)\n",
    "                negj = conditional_probability(data[EFFECT_COLUMN], negj)\n",
    "\n",
    "                # total_probability += k * (conj - negj)\n",
    "                total_probability += (conj - negj)\n",
    "\n",
    "            if (len(relateds) > 0): return total_probability / len(relateds)\n",
    "            return total_probability\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def is_binary_column(data, column_name):\n",
    "            # is_binary_column --\n",
    "            # Checks to see if a column is a column of 1s and 0s\n",
    "            # INPUT: [data] is a dataframe\n",
    "            # INPUT: [column_name] should be the name of a valid column in [data]\n",
    "            return data.apply(lambda row : 0 if (isinstance(row[column_name], int) and (row[column_name] <= 1)) else 1, axis=1).sum() <= 0\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def remove_non_binary_columns(data):\n",
    "            # remove_non_binary_columns --\n",
    "            # Removes all columns that are not 0s or 1s in the dataset\n",
    "            # INPUT: [data] is a dataframe\n",
    "            non_binary = []\n",
    "            for i in data.columns:\n",
    "                if i in [EFFECT_COLUMN, VALID_COLUMN]: continue\n",
    "                if not is_binary_column(data, i):\n",
    "                    non_binary.append(i)\n",
    "\n",
    "            return data.drop(columns=non_binary)\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def generate_row(data, column_name):\n",
    "            # generate_row --\n",
    "            # TODO: This is kind of a terrible name but I can't really think of anything more descriptive. If anyone has any ideas, feel free to modify it\n",
    "            # It basically creates a row, which is actually a data frame with all the data that is needed\n",
    "            # OUTPUT: It outputs a row with all the required values\n",
    "            # INPUT: [data] should be a dataframe\n",
    "            # INPUT: [column_name] should be a string representing a valid column in [data]\n",
    "            toReturn = pd.DataFrame({\n",
    "                \"name\": [column_name], \n",
    "                \"support\": conjunction(data[column_name], data[VALID_COLUMN]).sum(),\n",
    "                \"causality\": [calculate_causality(data, column_name)],\n",
    "                \"rel\": ','.join(rel(data, column_name)),\n",
    "                \"conditional_probability\":[conditional_probability(data[EFFECT_COLUMN], data[column_name])], \n",
    "                \"prior\": prior(data),\n",
    "                \"conditional - prior\": conditional_probability(data[EFFECT_COLUMN], data[column_name]) - prior(data)\n",
    "            })\n",
    "            return toReturn\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "\n",
    "        def causality_values(input_df):\n",
    "            # causality_values --\n",
    "            # Calculates causality values\n",
    "\n",
    "            # Then remove all the non binary columns\n",
    "            # input_df = remove_non_binary_columns(input_df)\n",
    "\n",
    "            # TODO: This is a hack\n",
    "            # short_names = []\n",
    "            # for column in input_df.columns:\n",
    "            #     if len(column) < 5 and column != VALID_COLUMN and column != EFFECT_COLUMN: short_names.append(column)\n",
    "            # input_df = input_df.drop(columns=short_names, axis=1)\n",
    "\n",
    "            # TODO: I'm not sure if there's another way to do this, so feel free to make modifications\n",
    "            # Generate a dud data frame with a single so we can append to it.\n",
    "            to_save = generate_row(input_df, VALID_COLUMN)\n",
    "            for column in input_df.columns:\n",
    "                if column in [VALID_COLUMN, EFFECT_COLUMN]: continue\n",
    "                to_save = pandas.concat([to_save, generate_row(input_df, column)], axis=0)\n",
    "\n",
    "            # Remove the dud first row\n",
    "            to_save = to_save[1:]\n",
    "            return to_save\n",
    "\n",
    "            \"\"\"\"\"\"\n",
    "\n",
    "        to_return = causality_values(input_df)\n",
    "        return to_return\n",
    "    \n",
    "SPIKES_COLUMNS = [BRENT_OIL_SPIKES_COLUMN, WTI_OIL_SPIKES_COLUMN, VALUE_SPIKES_COLUMN, QUANTITY_SPIKES_COLUMN, UNIT_RATE_SPIKES_COLUMN, 'spikes']\n",
    "aggregated_df_spikes = aggregated_df[SPIKES_COLUMNS]\n",
    "aggregated_df_spikes['VALID'] = 1\n",
    "aggregated_df_spikes\n",
    "Causality.causality_wrapper(aggregated_df_spikes, VALID_COLUMN='VALID', EFFECT_COLUMN='spikes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
