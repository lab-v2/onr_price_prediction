{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "analysis_dir_path = '../'\n",
    "sys.path.append(analysis_dir_path)\n",
    "\n",
    "import models\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 32\n",
    "kernels = 5\n",
    "units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = f'CNN_{filters}_filters_{kernels}_kernels_predictions'\n",
    "CNNA = f'CNN_Attention_{filters}_filters_{kernels}_kernels_predictions'\n",
    "RNN = f'RNN_{units}_units_predictions'\n",
    "LSTM = f'LSTM_{units}_layers_predictions'\n",
    "\n",
    "name_maps = {\n",
    "    CNN: \"CNN\",\n",
    "    CNNA: \"CNN With Attention\",\n",
    "    RNN: \"RNN\",\n",
    "    LSTM: \"LSTM\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, rule_result_column):\n",
    "    TP = ((df[rule_result_column] == 1) & (df['corr'] == 1)).sum()\n",
    "    FP = ((df[rule_result_column] == 1) & (df['corr'] == 0)).sum()\n",
    "    FN = ((df[rule_result_column] == 0) & (df['corr'] == 1)).sum()\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import example\n",
    "\n",
    "COMMODITY = 'nickel_no_val_20'\n",
    "MODEL = CNNA\n",
    "RULE_NUM = 10\n",
    "confidence_levels = [0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "def exclude_zero(series):\n",
    "    temp = series.copy()\n",
    "    temp = temp[temp != 0]\n",
    "    temp = temp[temp != 1]\n",
    "    return temp\n",
    "\n",
    "# A function for providing useful labels for the results\n",
    "def label(results, row):\n",
    "    labels = []\n",
    "    max_base_model_precision = exclude_zero(results[\"Precision (Base Model)\"]).max()\n",
    "    max_base_model_recall = exclude_zero(results[\"Recall (Base Model)\"]).max()\n",
    "    max_base_model_f1 = exclude_zero(results[\"F1 (Base Model)\"]).max()\n",
    "    min_base_model_f1 = exclude_zero(results[\"F1 (Base Model)\"]).min()\n",
    "\n",
    "    if max_base_model_precision == row[\"Precision (Base Model)\"]: labels.append(\"Best Precision\")\n",
    "    if max_base_model_recall == row[\"Recall (Base Model)\"]: labels.append(\"Best Recall\")\n",
    "    if max_base_model_f1 == row[\"F1 (Base Model)\"]: labels.append(\"Best F1\")\n",
    "    if min_base_model_f1 == row[\"F1 (Base Model)\"]: labels.append(\"Worst F1\")\n",
    "    return ', '.join(labels)\n",
    "\n",
    "def evaluate_df(df, properties={}):\n",
    "  f1, recall, precision = calculate_metrics(df, \"pred\")\n",
    "  prior = df[\"corr\"].sum() / len(df)\n",
    "  df.to_numpy().dump('data/test.npy')\n",
    "  df = example.run_edcr()\n",
    "\n",
    "  new_precision = df.iloc[50][\"pre\"]\n",
    "  new_recall = df.iloc[50][\"recall\"]\n",
    "  new_f1 = df.iloc[50][\"F1\"]\n",
    "\n",
    "  percent_precision = (new_precision - precision) / precision\n",
    "  percent_recall = (new_recall - recall) / recall\n",
    "  percent_f1 = (new_f1 - f1) / f1\n",
    "\n",
    "  return {\n",
    "    **properties,\n",
    "    \"Precision (Base Model)\": precision,\n",
    "    \"Recall (Base Model)\": recall,\n",
    "    \"F1 (Base Model)\": f1,\n",
    "    \"Prior\": prior,\n",
    "    \" \": \"\",\n",
    "    \"Precision (EDCR)\": df.iloc[50][\"pre\"],\n",
    "    \"Recall (EDCR)\": df.iloc[50][\"recall\"],\n",
    "    \"F1 (EDCR)\": df.iloc[50][\"F1\"],\n",
    "    \"  \": \"\",\n",
    "    \"Precision Improvement\": df.iloc[50][\"pre\"] - precision,\n",
    "    \"Recall Improvement\": df.iloc[50][\"recall\"] - recall,\n",
    "    \"F1 Improvement\": df.iloc[50][\"F1\"] - f1\n",
    "  }\n",
    "\n",
    "for COMMODITY in [\n",
    "  # 'cobalt_20'\n",
    "  # 'cobalt_20', 'cobalt_no_val_20', 'cobalt_shift_20', 'cobalt_streaming_20', 'cobalt_20',\n",
    "  # 'copper_20', 'copper_no_val_20', 'copper_shift_20', 'copper_streaming_20', 'copper_20',\n",
    "  # 'magnesium_20', 'magnesium_no_val_20', 'magnesium_shift_20', 'magnesium_streaming_20', 'magnesium_20',\n",
    "  # 'nickel_20', 'nickel_no_val_20', 'nickel_shift_20', 'nickel_streaming_20', 'nickel_20'\n",
    "  'cobalt_20', 'copper_20', 'magnesium_20', 'nickel_20', \n",
    "]:\n",
    "  results = []\n",
    "  for MODEL in [CNN, CNNA, RNN, LSTM]:\n",
    "  # for MODEL in [CNN]:\n",
    "    for ALGO in ['correction', 'detection_correction']:\n",
    "    # for ALGO in ['correction']:\n",
    "      for RULE_NUM in [5, 10, 15, 20, 50, 100]:\n",
    "      # for RULE_NUM in [5]:\n",
    "        df = models.npy_to_top_n_f1_bowpy(f'../{COMMODITY}/test/predictions/test/{MODEL}.csv', f'../{COMMODITY}/test/predictions/test_F1_{ALGO}', RULE_NUM)\n",
    "        results.append(evaluate_df(df, properties={\"Model\": MODEL, \"Algorithm\": ALGO, \"Rule Num\": RULE_NUM}))\n",
    "  results = pd.DataFrame(results)\n",
    "  results['Label'] = results.apply(lambda x: label(results, x), axis=1)\n",
    "  results.to_excel(f'out/top_f1/{COMMODITY}_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate_df() got an unexpected keyword argument 'properties'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m THRESHOLD \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.30\u001b[39m, \u001b[38;5;241m0.35\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.45\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# for RULE_NUM in [5]:\u001b[39;00m\n\u001b[0;32m     43\u001b[0m       df \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mnpy_to_threshold_f1_bowpy(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCOMMODITY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/predictions/test/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCOMMODITY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/predictions/test_F1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALGO\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, THRESHOLD, exclude_models\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m---> 44\u001b[0m       results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mevaluate_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAlgorithm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mALGO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThreshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTHRESHOLD\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     45\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m     46\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: label(results, x), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate_df() got an unexpected keyword argument 'properties'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import example\n",
    "\n",
    "COMMODITY = 'nickel_no_val_20'\n",
    "MODEL = CNNA\n",
    "RULE_NUM = 10\n",
    "confidence_levels = [0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "def exclude_zero(series):\n",
    "    temp = series.copy()\n",
    "    temp = temp[temp != 0]\n",
    "    temp = temp[temp != 1]\n",
    "    return temp\n",
    "\n",
    "# A function for providing useful labels for the results\n",
    "def label(results, row):\n",
    "    labels = []\n",
    "    max_base_model_precision = exclude_zero(results[\"Precision (Base Model)\"]).max()\n",
    "    max_base_model_recall = exclude_zero(results[\"Recall (Base Model)\"]).max()\n",
    "    max_base_model_f1 = exclude_zero(results[\"F1 (Base Model)\"]).max()\n",
    "    min_base_model_f1 = exclude_zero(results[\"F1 (Base Model)\"]).min()\n",
    "\n",
    "    if max_base_model_precision == row[\"Precision (Base Model)\"]: labels.append(\"Best Precision\")\n",
    "    if max_base_model_recall == row[\"Recall (Base Model)\"]: labels.append(\"Best Recall\")\n",
    "    if max_base_model_f1 == row[\"F1 (Base Model)\"]: labels.append(\"Best F1\")\n",
    "    if min_base_model_f1 == row[\"F1 (Base Model)\"]: labels.append(\"Worst F1\")\n",
    "    return ', '.join(labels)\n",
    "\n",
    "for COMMODITY in [\n",
    "  # 'cobalt_20'\n",
    "  # 'cobalt_20', 'cobalt_no_val_20', 'cobalt_shift_20', 'cobalt_streaming_20', 'cobalt_20',\n",
    "  # 'copper_20', 'copper_no_val_20', 'copper_shift_20', 'copper_streaming_20', 'copper_20',\n",
    "  # 'magnesium_20', 'magnesium_no_val_20', 'magnesium_shift_20', 'magnesium_streaming_20', 'magnesium_20',\n",
    "  # 'nickel_20', 'nickel_no_val_20', 'nickel_shift_20', 'nickel_streaming_20', 'nickel_20'\n",
    "  'cobalt_20', 'copper_20', 'magnesium_20', 'nickel_20', \n",
    "]:\n",
    "  results = []\n",
    "  for MODEL in [CNN, CNNA, RNN, LSTM]:\n",
    "  # for MODEL in [CNN]:\n",
    "    for ALGO in ['correction', 'detection_correction']:\n",
    "    # for ALGO in ['correction']:\n",
    "      for THRESHOLD in [0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5]:\n",
    "      # for RULE_NUM in [5]:\n",
    "        df = models.npy_to_threshold_f1_bowpy(f'../{COMMODITY}/test/predictions/test/{MODEL}.csv', f'../{COMMODITY}/test/predictions/test_F1_{ALGO}', THRESHOLD, exclude_models=[])\n",
    "        results.append(evaluate_df(df, properties={\"Model\": MODEL, \"Algorithm\": ALGO, \"Threshold\": THRESHOLD}))\n",
    "  results = pd.DataFrame(results)\n",
    "  results['Label'] = results.apply(lambda x: label(results, x), axis=1)\n",
    "  results.to_excel(f'out/threshold/{COMMODITY}_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
