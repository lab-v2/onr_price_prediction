{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "analysis_dir_path = '../'\n",
    "sys.path.append(analysis_dir_path)\n",
    "\n",
    "import models\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 32\n",
    "kernels = 5\n",
    "units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = f'CNN_{filters}_filters_{kernels}_kernels_predictions'\n",
    "CNNA = f'CNN_Attention_{filters}_filters_{kernels}_kernels_predictions'\n",
    "RNN = f'RNN_{units}_units_predictions'\n",
    "LSTM = f'LSTM_{units}_layers_predictions'\n",
    "\n",
    "name_maps = {\n",
    "    CNN: \"CNN\",\n",
    "    CNNA: \"CNN With Attention\",\n",
    "    RNN: \"RNN\",\n",
    "    LSTM: \"LSTM\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, rule_result_column):\n",
    "    TP = ((df[rule_result_column] == 1) & (df['corr'] == 1)).sum()\n",
    "    FP = ((df[rule_result_column] == 1) & (df['corr'] == 0)).sum()\n",
    "    FN = ((df[rule_result_column] == 0) & (df['corr'] == 1)).sum()\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import example\n",
    "\n",
    "COMMODITY = 'nickel_no_val_20'\n",
    "MODEL = CNNA\n",
    "RULE_NUM = 10\n",
    "confidence_levels = [0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "def exclude_zero(series):\n",
    "    temp = series.copy()\n",
    "    temp = temp[temp != 0]\n",
    "    temp = temp[temp != 1]\n",
    "    return temp\n",
    "\n",
    "# A function for providing useful labels for the results\n",
    "def label(results, row):\n",
    "    labels = []\n",
    "    max_base_model_precision = exclude_zero(results[\"Precision (Base Model)\"]).max()\n",
    "    max_base_model_recall = exclude_zero(results[\"Recall (Base Model)\"]).max()\n",
    "    max_base_model_f1 = exclude_zero(results[\"F1 (Base Model)\"]).max()\n",
    "    min_base_model_f1 = exclude_zero(results[\"F1 (Base Model)\"]).min()\n",
    "\n",
    "    if max_base_model_precision == row[\"Precision (Base Model)\"]: labels.append(\"Best Precision\")\n",
    "    if max_base_model_recall == row[\"Recall (Base Model)\"]: labels.append(\"Best Recall\")\n",
    "    if max_base_model_f1 == row[\"F1 (Base Model)\"]: labels.append(\"Best F1\")\n",
    "    if min_base_model_f1 == row[\"F1 (Base Model)\"]: labels.append(\"Worst F1\")\n",
    "    return ', '.join(labels)\n",
    "\n",
    "for COMMODITY in [\n",
    "  # 'cobalt_20'\n",
    "  'cobalt_20', 'cobalt_no_val_20', 'cobalt_shift_20', 'cobalt_streaming_20', 'cobalt_20',\n",
    "  'copper_20', 'copper_no_val_20', 'copper_shift_20', 'copper_streaming_20', 'copper_20',\n",
    "  'magnesium_20', 'magnesium_no_val_20', 'magnesium_shift_20', 'magnesium_streaming_20', 'magnesium_20',\n",
    "  'nickel_20', 'nickel_no_val_20', 'nickel_shift_20', 'nickel_streaming_20', 'nickel_20'\n",
    "]:\n",
    "  results = []\n",
    "  for MODEL in [CNN, CNNA, RNN, LSTM]:\n",
    "  # for MODEL in [CNN]:\n",
    "    for ALGO in ['correction', 'detection_correction']:\n",
    "    # for ALGO in ['correction']:\n",
    "      for RULE_NUM in [5, 10, 15, 20, 50, 100]:\n",
    "      # for RULE_NUM in [5]:\n",
    "        df = models.npy_to_top_n_f1_bowpy(f'../{COMMODITY}/test/predictions/test/{MODEL}.csv', f'../{COMMODITY}/test/predictions/test_F1_{ALGO}', RULE_NUM)\n",
    "        f1, recall, precision = calculate_metrics(df, \"pred\")\n",
    "        df.to_numpy().dump('data/test.npy')\n",
    "        df = example.run_edcr(return_type=\"np\")\n",
    "        results.append({\n",
    "          \"Base Model\": name_maps[MODEL],\n",
    "          \"Number of rules\": RULE_NUM,\n",
    "          \"Algorithm\": ALGO,\n",
    "          \"Precision (Base Model)\": precision,\n",
    "          \"Recall (Base Model)\": recall,\n",
    "          \"F1 (Base Model)\": f1,\n",
    "          \" \": \"\",\n",
    "          \"Precision (EDCR)\": df.iloc[50][\"pre\"],\n",
    "          \"Recall (EDCR)\": df.iloc[50][\"recall\"],\n",
    "          \"F1 (EDCR)\": df.iloc[50][\"F1\"],\n",
    "          \"  \": \"\",\n",
    "          \"Precision Improvement\": df.iloc[50][\"pre\"] - precision,\n",
    "          \"Recall Improvement\": df.iloc[50][\"recall\"] - recall,\n",
    "          \"F1 Improvement\": df.iloc[50][\"F1\"] - f1\n",
    "        })\n",
    "        display(df.iloc[50])\n",
    "  results = pd.DataFrame(results)\n",
    "  results['Label'] = results.apply(lambda x: label(results, x), axis=1)\n",
    "  results.to_excel(f'out/{COMMODITY}_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
